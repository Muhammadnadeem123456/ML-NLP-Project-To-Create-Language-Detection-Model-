{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53ebff0-8cf2-4cce-8980-07d017972809",
   "metadata": {},
   "source": [
    "# Machine Learning & NLP Full Project | How to Creat|e Language Detection Model | Google Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0be1d5ba-da5c-4b6e-903f-25e509489d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  language\n",
       "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4  de spons behoort tot het geslacht haliclona en...     Dutch"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "df=pd.read_csv(\"language.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4190ec3d-45b6-4e27-bd2a-6f71c5262d6a",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer ka matlab hai ki aap scikit-leam library ke feature_extraction.text module se CountVectorizer class ko import kar rahe ho\n",
    "\n",
    "CountVectorizer kya karta hai? CountVectorizer ek tool hai jo text data ko numerical data mein convert karta hai. Yeh text ke har unique word ko count karta hai aur unhe ek matrix ke form mein store karta hai, jise bag-of-words (BoW) representation bhi kehte hain.\n",
    "\n",
    "Bag of Words (BoW) ek fundamental technique hai jo text data ko numerical format mein convert karti hai, taaki usko machine leaming models ke liye use kiya ja sake. BoW approach mein, ek text ko usme aaye unique words aur unke counts ke through represent kiya jata hai.\n",
    "\n",
    "Is approach mein text ke grammar, word order ya context ka koi dhyaan nahi rakha jata, sirf yeh dekha jata hai ki kaunse words kitni baar aaye hain. Words ke count ko hi important feature mana jata hai.\n",
    "\n",
    "Bag of Words ka Concept: Bag ka matlab hota hai ki words ko ek collection (ya bag) ke form mein dekha jata hai, bina kisi specific order ke Words ka matlab hal text mein aaye words (terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e7d09df-7cce-4a3e-8412-67e932cc3f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deep' 'learning' 'love' 'nlp']\n",
      "[[1 1 1 0]\n",
      " [0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#bag of word...\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#create count vectorizer \n",
    "vectorizer = CountVectorizer()\n",
    "data = [\"I love deep learning\", \"I love nlp\"]\n",
    "#fit and transform \n",
    "vectorizer_data=vectorizer.fit_transform(data)\n",
    "#get vocabulary unique words\n",
    "print(vectorizer.get_feature_names_out())\n",
    "#convert the result to an array\n",
    "print(vectorizer_data.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794f1a17-6f70-4498-8373-1564a9f890f8",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import MultinomialNB ka matlab hai ki aap scikit-learn library ke naive_bayes module se MultinomialNB class ko import kar rahe hain.\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "Iska matlab hai ki aap scikit-learn library ke andar ek special algorithm Multinomial Naive Bayes (MultinomialNB) ko use karne ja rahe ho. Yeh ek tarah ka machine learning algorithm hai jo mainly text classification ke liye use hota hai, jaise:\n",
    "\n",
    "Spam ya Not Spam emails ka classification. Positive ya Negative reviews ko alag kama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3a29728-c90a-4775-a55d-e139802c91c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Sample emails \n",
    "emails=[\"I love learning\", \"Click here to win money\", \"Learning is fun\", \"Get soon now\"]\n",
    "labels=[0, 1, 8, 1]   #8 means not spam, 1 means spam\n",
    "\n",
    "# Step 1: Convert text into numbers (word counts) \n",
    "vectorizer=CountVectorizer()\n",
    "\n",
    "X= vectorizer.fit_transform(emails)\n",
    "\n",
    "#Step 2: Train the MultinomiaLNB model\n",
    "model=MultinomialNB()\n",
    "model.fit(X, labels)\n",
    "\n",
    "# Step 3: Predict if a new email is span or not\n",
    "new_email=[\"Win money now!\"]\n",
    "new_email_vector=vectorizer.transform(new_email)\n",
    "prediction=model.predict(new_email_vector)\n",
    "\n",
    "print(\"Prediction:\", prediction)\n",
    "# means spom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca3fe7-725b-4e28-a475-018a45e72e89",
   "metadata": {},
   "source": [
    "pandas as pd: Imports the pandas library, which is used for data manipulation and analysis, particularly for handling data in tables (DataFrames).\n",
    "\n",
    "numpy as np: Imports numpy, which is a library for numerical computations. It's used for working with arrays and matrices,\n",
    "\n",
    "CountVectorizer. This is a tool from the sklearn.feature extraction.text module. It converts text data into a matrix of token counts (bag of words model).\n",
    "\n",
    "train_test_split: A function from sklearn.model_selection that splits data into training and testing sets.\n",
    "\n",
    "MultinomialNB: This is the Naive Bayes classifier for multinomially distributed data, often used for text classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c5fff4b-1560-483e-a505-fa9969159511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "language    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad4858cf-6f45-4ae5-a293-d54afa1a236c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "Estonian      1000\n",
       "Swedish       1000\n",
       "Thai          1000\n",
       "Tamil         1000\n",
       "Dutch         1000\n",
       "Japanese      1000\n",
       "Turkish       1000\n",
       "Latin         1000\n",
       "Urdu          1000\n",
       "Indonesian    1000\n",
       "Portugese     1000\n",
       "French        1000\n",
       "Chinese       1000\n",
       "Korean        1000\n",
       "Hindi         1000\n",
       "Spanish       1000\n",
       "Pushto        1000\n",
       "Persian       1000\n",
       "Romanian      1000\n",
       "Russian       1000\n",
       "English       1000\n",
       "Arabic        1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31f26973-35c3-49cc-bd3b-3ea4df845ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemärke  aastal viidi ta surnukeha mausoleumist ära ja kremeeriti zlíni linn kandis aastatel – nime gottwaldov ukrainas harkivi oblastis kandis zmiivi linn aastatel – nime gotvald'\n",
      " 'sebes joseph pereira thomas  på eng the jesuits and the sino-russian treaty of nerchinsk  the diary of thomas pereira bibliotheca instituti historici s i --   rome libris '\n",
      " 'ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เริ่มตั้งแต่ถนนสนามไชยถึงแม่น้ำเจ้าพระยาที่ถนนตก กรุงเทพมหานคร เป็นถนนรุ่นแรกที่ใช้เทคนิคการสร้างแบบตะวันตก ปัจจุบันผ่านพื้นที่เขตพระนคร เขตป้อมปราบศัตรูพ่าย เขตสัมพันธวงศ์ เขตบางรัก เขตสาทร และเขตบางคอแหลม'\n",
      " ...\n",
      " 'con motivo de la celebración del septuagésimoquinto ° aniversario de la fundación del departamento en  guillermo ceballos espinosa presentó a la gobernación de caldas por encargo de su titular dilia estrada de gómez el himno que fue adoptado para solemnizar dicha efemérides y que siguieron interpretando las bandas de música y los planteles de educación de esta sección del país en retretas y actos oficiales con gran aceptación[]\\u200b'\n",
      " '年月，當時還只有歲的她在美國出道，以mai-k名義推出首張英文《baby i like》，由美國的獨立廠牌bip·record發行，以外國輸入盤的形式在日本發售，旋即被抢购一空。其後於月日發行以倉木麻衣名義發行的首張日文單曲《love day after tomorrow》，正式於日本出道。這張單曲初動銷量只得約萬張，可是其後每週銷量一直上升，並於年月正式突破百萬銷量，合计万张。成為年最耀眼的新人歌手。'\n",
      " ' aprilie sonda spațială messenger a nasa și-a încheiat misiunea de studiu de  ani prăbușindu-se pe suprafața planetei mercur sonda a rămas fără combustibil fiind împinsă de gravitația solară din ce în ce mai aproape de mercur']\n"
     ]
    }
   ],
   "source": [
    "x=np.array(df[\"Text\"])\n",
    "y=np.array(df[\"language\"])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b3e897-0aea-48d9-9ef1-9fa35a6e1013",
   "metadata": {},
   "source": [
    "['klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeh a oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagune mise tundemärke aastal viidi ta surnukeha mausoleumist ära ja kremeeriti zlí ni linn kandis aastatel nime gottwaldov ukrainas harkivi oblastis kandis zm iivi linn aastatel nime gotvald\n",
    "\n",
    "sebes joseph pereira thomas på eng the jesuits and the sino-russian treaty of nerchinsk the diary of thomas pereira bibliotheca instituti historici s i rome libris\n",
    "\n",
    "\"ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เริ่มตั้งแต่ถนนสนามไชยถึงแม่น้ำเจ้าพระยาที่ถ นนตก กรุงเทพมหานคร เป็นถนนรุ่นแรกที่ไช่เทคนิคการสร้างแบบตะวันตก ปัจจุบันผ่านพื้นที่เขตพระนคร เขตป้อมปราบศัตรูพ่าย เขตสัมพันธวงศ์ เขตบางรัก เขตสาทร และเขตบางคอแหลม\n",
    "\n",
    "con motivo de la celeración del septuagésimoquinto aniversario de la fun dación del departamento en guillermo ceballos espinosa presentó a la goberna ción de caldas por encargo de su titular dilia estrada de gómez el himno que fue adoptado para solemnizar dicha efemérides y que siguieron interpretando 1 as bandas de música y los planteles de educación de esta sección del país en retretas y actos oficiales con gran aceptación[]\\u200b\n",
    "\n",
    "「年月,當時還只有歲的她在美國出道,以mai-k名義推出首張英文《baby i like》,由美國 的獨立廠牌bip-record發行,以外國輸入盤的形式在日本發售,旋即被抢购一空,其後於月日 發行以倉木麻衣名義發行的首張日文單曲《love day after tomorrow),正式於日本出道。 這張單曲初動銷量只得約萬張,可是其後每週銷量一直上升,並於年月正式突破百萬銷量,合计\n",
    "\n",
    "aprilie sonda spațială messenger a nasa şi-a încheiat misiunea de studiu d e ani prăbuşindu-se pe suprafața planetei mercur sonda a rămas fără combusti bil fiind impinsă de gravitația solară din ce in ce mai aproape de mercur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5253fe1-e439-4cf1-a9ce-9173ea87ebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Estonian' 'Swedish' 'Thai' ... 'Spanish' 'Chinese' 'Romanian']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2a3b8a3-043e-4647-b843-2556d6631bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Create CountVectorizer instance\n",
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "202570db-82c4-4919-9612-69c469f6c2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953168044077135"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
